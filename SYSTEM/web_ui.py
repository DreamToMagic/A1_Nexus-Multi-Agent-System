import os
import sys
import gradio as gr
from pathlib import Path
import threading
import time
import re
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# å¯¼å…¥æ ¸å¿ƒå¼•æ“
from nexus_core import NexusEngine, ConfigManager

# åˆå§‹åŒ–å¼•æ“
engine = NexusEngine(auto_mode=True)
config_mgr = ConfigManager()

def get_system_status():
    """è·å–ç³»ç»Ÿå½“å‰çŠ¶æ€"""
    tasks = engine.parse_tasks()
    
    # ç»Ÿè®¡ä»»åŠ¡çŠ¶æ€
    total = len(tasks)
    done = sum(1 for t in tasks if "DONE" in t["status"].upper())
    new = sum(1 for t in tasks if "NEW" in t["status"].upper())
    
    # è·å–å½’æ¡£ä»»åŠ¡æ•°
    archived = len(list(engine.archive_dir.glob("*.md")))
    
    status_text = f"ğŸ“Š **ç³»ç»ŸçŠ¶æ€**: å…± {total} ä¸ªæ´»è·ƒä»»åŠ¡ | âœ… å·²å®Œæˆ: {done} | â³ å¾…æ‰§è¡Œ: {new} | ğŸ“¦ å·²å½’æ¡£: {archived}"
    return status_text

def get_task_list():
    """è·å–ä»»åŠ¡åˆ—è¡¨ç”¨äºå±•ç¤º"""
    tasks = engine.parse_tasks()
    if not tasks:
        return "å½“å‰æ²¡æœ‰æ´»è·ƒä»»åŠ¡ã€‚"
        
    markdown_list = "### ğŸ“‹ ä»»åŠ¡çœ‹æ¿\n\n"
    markdown_list += "| çŠ¶æ€ | ä»»åŠ¡ ID | æ¥æ”¶è€… | ä¾èµ–é¡¹ | æ–‡ä»¶å |\n"
    markdown_list += "|---|---|---|---|---|\n"
    
    for t in tasks:
        status_icon = "ğŸŸ¢" if "DONE" in t["status"].upper() else "ğŸŸ¡"
        deps = ", ".join(t["depends_on"]) if t["depends_on"] else "æ— "
        markdown_list += f"| {status_icon} {t['status']} | **{t['id']}** | {t['receiver']} | {deps} | `{t['filename']}` |\n"
        
    return markdown_list

def run_one_step():
    """æ‰§è¡Œä¸€æ­¥ä»»åŠ¡"""
    engine.archive_done_tasks()
    tasks = engine.parse_tasks()
    
    if not tasks:
        return "âœ… å½“å‰æ²¡æœ‰ä»»åŠ¡éœ€è¦æ‰§è¡Œã€‚"
        
    runnable_tasks = engine.get_runnable_tasks(tasks)
    if not runnable_tasks:
        return "â³ å½“å‰æ²¡æœ‰å¯ç«‹å³æ‰§è¡Œçš„ä»»åŠ¡ï¼ˆå¯èƒ½éƒ½åœ¨ç­‰å¾…å‰ç½®ä¾èµ–å®Œæˆï¼‰ã€‚"
        
    target_task = runnable_tasks[0]
    log_msg = f"ğŸš€ æ­£åœ¨æ‰§è¡Œä»»åŠ¡: **{target_task['id']}** (ç”± {target_task['receiver']} è´Ÿè´£)...\n\n"
    
    # æ•è·æ ‡å‡†è¾“å‡ºä»¥æ˜¾ç¤ºåœ¨ UI ä¸­
    import io
    from contextlib import redirect_stdout
    
    f = io.StringIO()
    with redirect_stdout(f):
        success = engine.execute_task(target_task)
        
    output = f.getvalue()
    
    # è®°å½•å·¥ä½œå†å²
    re d_work_history(target_task, success)
    
    if success:
        return log_msg + "âœ… ä»»åŠ¡æ‰§è¡ŒæˆåŠŸï¼\n\n" + "```text\n" + output + "\n```"
    else:
        return log_msg + "âŒ ä»»åŠ¡æ‰§è¡Œå¤±è´¥ã€‚\n\n" + "```text\n" + output + "\n```"

# å…¨å±€å˜é‡æ§åˆ¶è‡ªåŠ¨è¿è¡ŒçŠ¶æ€
auto_run_flag = False

def toggle_auto_run():
    """åˆ‡æ¢è‡ªåŠ¨è¿è¡ŒçŠ¶æ€"""
    global auto_run_flag
    auto_run_flag = not auto_run_flag
    if auto_run_flag:
        return "â¸ï¸ æš‚åœè‡ªåŠ¨æ‰§è¡Œ", "ğŸš€ è‡ªåŠ¨æµæ°´çº¿å·²å¯åŠ¨..."
    else:
        return "ğŸš€ ä¸€é”®å…¨è‡ªåŠ¨æ‰§è¡Œ", "â¸ï¸ è‡ªåŠ¨æµæ°´çº¿å·²æš‚åœã€‚"

def auto_run_all(progress=gr.Progress()):
    """å…¨è‡ªåŠ¨æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡"""
    global auto_run_flag
    if not auto_run_flag:
        yield "â¸ï¸ è‡ªåŠ¨æµæ°´çº¿å·²æš‚åœã€‚"
        return
        
    log_output = "ğŸš€ å¼€å§‹å…¨è‡ªåŠ¨æµæ°´çº¿...\n\n"
    yield log_output
    
    while auto_run_flag:
        engine.archive_done_tasks()
        tasks = engine.parse_tasks()
        
        if not tasks:
            log_output += "âœ… æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆï¼\n"
            auto_run_flag = False
            yield log_output
            break
            
        runnable_tasks = engine.get_runnable_tasks(tasks)
        if not runnable_tasks:
            log_output += "â³ æ²¡æœ‰å¯æ‰§è¡Œçš„ä»»åŠ¡ï¼Œæµæ°´çº¿åœæ­¢ã€‚\n"
            auto_run_flag = False
            yield log_output
            break
            
        target_task = runnable_tasks[0]
        progress(0, desc=f"æ­£åœ¨æ‰§è¡Œ: {target_task['id']}")
        
        log_output += f"â–¶ï¸ æ‰§è¡Œä»»åŠ¡: {target_task['id']} ({target_task['receiver']})\n"
        yield log_output
        
        # æ•è·è¾“å‡º
        import io
        from contextlib import redirect_stdout
        f = io.StringIO()
        with redirect_stdout(f):
            success = engine.execute_task(target_task)
            
        output = f.getvalue()
        
        if not success:
            log_output += f"âŒ ä»»åŠ¡æ‰§è¡Œå¤±è´¥ï¼Œæµæ°´çº¿ä¸­æ­¢ã€‚\n\n{output}\n"
            auto_run_flag = False
            yield log_output
            break
            
        log_output += f"âœ… ä»»åŠ¡å®Œæˆã€‚\n\n{output}\n"
        yield log_output
        
        # è®°å½•å·¥ä½œå†å²
        record_work_history(target_task, success)
        
        time.sleep(1) # ç¨å¾®æš‚åœä¸€ä¸‹ï¼Œé¿å… API é¢‘ç‡è¿‡é«˜

def get_work_history():
    """è·å–å·¥ä½œå†å²è®°å½•"""
    history_file = Path("SYSTEM/work_history.json")
    if not history_file.exists():
        return []
    try:
        import json
        with open(history_file, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return []

def record_work_history(task, success):
    """è®°å½•å·¥ä½œå†å²"""
    history_file = Path("SYSTEM/work_history.json")
    history = get_work_history()
    
    import datetime
    now = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    record = {
        "time": now,
        "task_id": task.get("id", "Unknown"),
        "receiver": task.get("receiver", "Unknown"),
        "status": "Success" if success else "Failed",
        "filename": task.get("filename", "Unknown")
    }
    
    history.insert(0, record) # æ’å…¥åˆ°æœ€å‰é¢
    # ä¿ç•™æœ€è¿‘ 100 æ¡è®°å½•
    history = history[:100]
    
    try:
        import json
        with open(history_file, "w", encoding="utf-8") as f:
            json.dump(history, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"è®°å½•å·¥ä½œå†å²å¤±è´¥: {e}")

def format_history_direct():
    """ç›´æ¥æ ¼å¼åŒ–å†å²è®°å½•"""
    history = get_work_history()
    if not history:
        return "æš‚æ— å·¥ä½œè®°å½•ã€‚"
        
    md = "### ğŸ“‹ åŸå§‹å·¥ä½œè®°å½•\n\n"
    md += "| æ—¶é—´ | ä»»åŠ¡ ID | æ‰§è¡Œè€… | çŠ¶æ€ | æ–‡ä»¶å |\n"
    md += "|---|---|---|---|---|\n"
    
    for r in history:
        status_icon = "âœ…" if r["status"] == "Success" else "âŒ"
        md += f"| {r['time']} | **{r['task_id']}** | {r['receiver']} | {status_icon} {r['status']} | `{r['filename']}` |\n"
        
    return md

def format_history_translated(progress=gr.Progress()):
    """AI ç¿»è¯‘å†å²è®°å½•ä¸ºäººè¯"""
    history = get_work_history()
    if not history:
        return "æš‚æ— å·¥ä½œè®°å½•ã€‚"
        
    progress(0, desc="æ­£åœ¨è°ƒç”¨ AI ç¿»è¯‘å·¥ä½œè®°å½•...")
    
    # å–æœ€è¿‘ 10 æ¡è®°å½•è¿›è¡Œç¿»è¯‘ï¼Œé¿å… token è¿‡å¤š
    recent_history = history[:10]
    import json
    history_str = json.dumps(recent_history, ensure_ascii=False, indent=2)
    
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªé€šä¿—æ˜“æ‡‚çš„é¡¹ç›®æ±‡æŠ¥åŠ©æ‰‹ã€‚
è¯·å°†ä»¥ä¸‹ JSON æ ¼å¼çš„ç³»ç»Ÿå·¥ä½œè®°å½•ï¼Œç¿»è¯‘æˆä¸€æ®µè¿è´¯ã€æ˜“æ‡‚çš„â€œäººè¯â€æ±‡æŠ¥ã€‚
è®©ä¸æ‡‚æŠ€æœ¯çš„ç”¨æˆ·ä¹Ÿèƒ½æ˜ç™½ç³»ç»Ÿåˆšæ‰åšäº†ä»€ä¹ˆã€‚
ä¾‹å¦‚ï¼šâ€œåœ¨ä¸‹åˆ3ç‚¹ï¼ŒæŠ€æœ¯ä¸»ç®¡æˆåŠŸå®Œæˆäº†åŸºç¡€æ¡†æ¶çš„æ­å»ºï¼ˆä»»åŠ¡ID001ï¼‰...â€
è¯·ç›´æ¥è¾“å‡ºæ±‡æŠ¥å†…å®¹ï¼Œä¸è¦åŒ…å«ä»»ä½•å¤šä½™çš„è§£é‡Šã€‚"""

    provider_name, provider_cfg, model_name = config_mgr.get_provider_config("P1_Nexus")
    
    from openai import OpenAI
    client = OpenAI(
        api_key=provider_cfg["api_key"],
        base_url=provider_cfg["base_url"]
    )
    
    try:
        response = client.chat.completions.create(
            model=model_name,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"è¯·ç¿»è¯‘ä»¥ä¸‹è®°å½•ï¼š\n\n{history_str}"}
            ],
            temperature=0.5
        )
        
        progress(1.0, desc="ç¿»è¯‘å®Œæˆï¼")
        return f"### ğŸ—£ï¸ AI æ±‡æŠ¥ (æœ€è¿‘ 10 æ¡)\n\n{response.choices[0].message.content}"
    except Exception as e:
        return f"âŒ ç¿»è¯‘å¤±è´¥: {e}\n\nè¯·æ£€æŸ¥ API é…ç½®æˆ–ç½‘ç»œè¿æ¥ã€‚"

def create_new_task(receiver, task_desc, depends_on, task_id=None):
    """åˆ›å»ºä¸€ä¸ªæ–°ä»»åŠ¡"""
    if not receiver or not task_desc:
        return "âŒ æ¥æ”¶è€…å’Œä»»åŠ¡æè¿°ä¸èƒ½ä¸ºç©ºï¼"
        
    # ç”Ÿæˆä»»åŠ¡ ID
    if not task_id:
        tasks = engine.parse_tasks()
        existing_ids = [int(re.search(r'\d+', t['id']).group()) for t in tasks if re.search(r'\d+', t['id'])]
        next_id = max(existing_ids) + 1 if existing_ids else 1
        task_id = f"ID{next_id:03d}"
    
    # æ ¼å¼åŒ–ä¾èµ–
    deps_str = depends_on if depends_on else "NONE"
    
    # ç”Ÿæˆæ–‡ä»¶å
    short_desc = task_desc[:10].replace(" ", "_").replace("\n", "")
    filename = f"[NEW]P1_TO_{receiver}_{task_id}_{short_desc}.md"
    filepath = engine.messages_dir / filename
    
    # å†™å…¥æ–‡ä»¶
    content = f"""# ä»»åŠ¡ç›®æ ‡ï¼š{task_desc.split(chr(10))[0]}

**DEPENDS_ON: {deps_str}**

## è¯¦ç»†è¦æ±‚
{task_desc}
"""
    with open(filepath, "w", encoding="utf-8") as f:
        f.write(content)
        
    return f"âœ… æˆåŠŸåˆ›å»ºä»»åŠ¡: {filename}"

def auto_breakdown_task(macro_task_desc, progress=gr.Progress()):
    """P1 è‡ªåŠ¨æ‹†è§£å®è§‚ä»»åŠ¡ä¸ºå¤šä¸ªå­ä»»åŠ¡"""
    if not macro_task_desc:
        return "âŒ å®è§‚ä»»åŠ¡æè¿°ä¸èƒ½ä¸ºç©ºï¼"
        
    progress(0, desc="æ­£åœ¨è°ƒç”¨ P1 æ€è€ƒæ‹†è§£æ–¹æ¡ˆ...")
    
    # è·å–å½“å‰å¯ç”¨çš„è§’è‰²åˆ—è¡¨
    available_personas = [p.stem for p in engine.personas_dir.glob("*.md")]
    personas_str = ", ".join(available_personas) if available_personas else "P8_æŠ€æœ¯, P8_æ–‡æ¡ˆ, P9_è¡Œæ”¿åˆè§„å®¡è®¡"
    
    # æ„é€  P1 çš„ Prompt
    system_prompt = f"""ä½ æ˜¯ P1-é¦–å¸­æ‰§è¡Œæ¶æ„å¸ˆ (Nexus-001)ã€‚
ä½ çš„ä»»åŠ¡æ˜¯å°†ç”¨æˆ·çš„å®å¤§ç›®æ ‡æ‹†è§£ä¸ºå¤šä¸ªå­ä»»åŠ¡ï¼Œä¸‹å‘ç»™å„ä¸ªè™šæ‹Ÿå‘˜å·¥ã€‚
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¾“å‡ºæ‹†è§£åçš„ä»»åŠ¡åˆ—è¡¨ï¼Œä¸è¦è¾“å‡ºä»»ä½•å…¶ä»–åºŸè¯ï¼š
[
  {{
    "receiver": "P8_æŠ€æœ¯ä¸»ç®¡",
    "depends_on": "NONE",
    "description": "æ­å»ºåŸºç¡€æ¡†æ¶..."
  }},
  {{
    "receiver": "P8_æ–‡æ¡ˆä¸»ç®¡",
    "depends_on": "ID001",
    "description": "ç¼–å†™æ–‡æ¡ˆ..."
  }}
]
æ³¨æ„ï¼š
1. receiver å¿…é¡»æ˜¯ç°æœ‰çš„è§’è‰²åï¼Œå½“å‰å¯ç”¨çš„è§’è‰²æœ‰ï¼š{personas_str}ã€‚
2. depends_on å¦‚æœæ²¡æœ‰ä¾èµ–å¡« NONEï¼Œå¦‚æœæœ‰ä¾èµ–å¡«å¯¹åº”çš„ IDï¼ˆå¦‚ ID001ï¼‰ã€‚ID æ˜¯æŒ‰é¡ºåºç”Ÿæˆçš„ï¼Œç¬¬ä¸€ä¸ªä»»åŠ¡æ˜¯ ID001ï¼Œç¬¬äºŒä¸ªæ˜¯ ID002ï¼Œä¾æ­¤ç±»æ¨ã€‚
"""
    
    # è·å– P1 çš„æ¨¡å‹é…ç½®
    provider_name, provider_cfg, model_name = config_mgr.get_provider_config("P1_Nexus")
    
    from openai import OpenAI
    client = OpenAI(
        api_key=provider_cfg["api_key"],
        base_url=provider_cfg["base_url"]
    )
    
    try:
        response = client.chat.completions.create(
            model=model_name,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"è¯·æ‹†è§£ä»¥ä¸‹å®è§‚ä»»åŠ¡ï¼š\n\n{macro_task_desc}"}
            ],
            temperature=0.2
        )
        
        result_text = response.choices[0].message.content
        
        # å°è¯•è§£æ JSON
        import json
        # æå– JSON éƒ¨åˆ† (é˜²æ­¢æ¨¡å‹è¾“å‡ºå¸¦æœ‰ markdown æ ‡è®°)
        json_match = re.search(r'\[.*\]', result_text, re.DOTALL)
        if json_match:
            json_str = json_match.group(0)
        else:
            json_str = result_text
            
        # è¿›ä¸€æ­¥æ¸…ç†ï¼Œç¡®ä¿åªåŒ…å« JSON æ•°ç»„
        start_idx = json_str.find('[')
        end_idx = json_str.rfind(']')
        if start_idx != -1 and end_idx != -1:
            json_str = json_str[start_idx:end_idx+1]
            
        tasks_data = json.loads(json_str)
        
        progress(0.5, desc="æ­£åœ¨ç”Ÿæˆä»»åŠ¡æ–‡ä»¶...")
        
        created_files = []
        for i, task_data in enumerate(tasks_data):
            receiver = task_data.get("receiver", "P8_æŠ€æœ¯")
            depends_on = task_data.get("depends_on", "NONE")
            desc = task_data.get("description", "")
            task_id = task_data.get("id", None)
            
            # ä¿®æ­£ä¾èµ– ID (å¦‚æœæ¨¡å‹ç”Ÿæˆçš„ä¾èµ– ID ä¸å‡†ç¡®ï¼Œè¿™é‡Œå¯ä»¥åšä¸€äº›å®¹é”™ï¼Œä½†ç›®å‰å…ˆä¿¡ä»»æ¨¡å‹)
            if isinstance(depends_on, list):
                depends_on = ", ".join(depends_on)
            
            res = create_new_task(receiver, desc, depends_on, task_id)
            created_files.append(res)
            
        progress(1.0, desc="æ‹†è§£å®Œæˆï¼")
        return "âœ… è‡ªåŠ¨æ‹†è§£å®Œæˆï¼\n\n" + "\n".join(created_files)
        
    except Exception as e:
        return f"âŒ è‡ªåŠ¨æ‹†è§£å¤±è´¥: {e}\n\næ¨¡å‹è¿”å›å†…å®¹:\n{result_text if 'result_text' in locals() else 'æ— '}"

def get_config_yaml():
    """è¯»å– config.yaml å†…å®¹"""
    config_path = Path("SYSTEM/config.yaml")
    if not config_path.exists():
        config_path = Path("config.yaml")
    if config_path.exists():
        with open(config_path, "r", encoding="utf-8") as f:
            return f.read()
    return "é…ç½®æ–‡ä»¶ä¸å­˜åœ¨"

def save_config_yaml(content):
    """ä¿å­˜ config.yaml å†…å®¹"""
    config_path = Path("SYSTEM/config.yaml")
    if not config_path.exists():
        config_path = Path("config.yaml")
    try:
        with open(config_path, "w", encoding="utf-8") as f:
            f.write(content)
        # é‡æ–°åŠ è½½é…ç½®
        global config_mgr
        config_mgr = ConfigManager()
        return "âœ… é…ç½®ä¿å­˜æˆåŠŸï¼"
    except Exception as e:
        return f"âŒ ä¿å­˜å¤±è´¥: {e}"

def get_personas_list():
    """è·å–è§’è‰²åˆ—è¡¨"""
    personas = []
    for p_file in engine.personas_dir.glob("*.md"):
        personas.append(p_file.name)
    return personas

def get_persona_content(filename):
    """è¯»å–è§’è‰²æ–‡ä»¶å†…å®¹"""
    if not filename:
        return ""
    filepath = engine.personas_dir / filename
    if filepath.exists():
        with open(filepath, "r", encoding="utf-8") as f:
            return f.read()
    return ""

def save_persona_content(filename, content):
    """ä¿å­˜è§’è‰²æ–‡ä»¶å†…å®¹"""
    if not filename:
        return "âŒ è¯·å…ˆé€‰æ‹©ä¸€ä¸ªè§’è‰²æ–‡ä»¶"
    filepath = engine.personas_dir / filename
    try:
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(content)
        return f"âœ… è§’è‰² {filename} ä¿å­˜æˆåŠŸï¼"
    except Exception as e:
        return f"âŒ ä¿å­˜å¤±è´¥: {e}"

def create_new_persona(filename, content):
    """åˆ›å»ºæ–°è§’è‰²"""
    if not filename:
        return "âŒ æ–‡ä»¶åä¸èƒ½ä¸ºç©º", gr.update()
    if not filename.endswith(".md"):
        filename += ".md"
    filepath = engine.personas_dir / filename
    if filepath.exists():
        return f"âŒ è§’è‰² {filename} å·²å­˜åœ¨", gr.update()
    try:
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(content)
        return f"âœ… è§’è‰² {filename} åˆ›å»ºæˆåŠŸï¼", gr.update(choices=get_personas_list(), value=filename)
    except Exception as e:
        return f"âŒ åˆ›å»ºå¤±è´¥: {e}", gr.update()

def get_workspace_files():
    """è·å–å·¥ä½œåŒºæ–‡ä»¶æ ‘"""
    tree_str = "### ğŸ“ PROJECT_SPACE ç›®å½•ç»“æ„\n```text\n"
    
    def build_tree(dir_path, prefix=""):
        nonlocal tree_str
        try:
            items = list(dir_path.iterdir())
            items.sort(key=lambda x: (not x.is_dir(), x.name))
            
            for i, item in enumerate(items):
                is_last = i == len(items) - 1
                connector = "â””â”€â”€ " if is_last else "â”œâ”€â”€ "
                
                if item.is_dir():
                    tree_str += f"{prefix}{connector}ğŸ“‚ {item.name}/\n"
                    extension = "    " if is_last else "â”‚   "
                    build_tree(item, prefix + extension)
                else:
                    tree_str += f"{prefix}{connector}ğŸ“„ {item.name}\n"
        except Exception as e:
            tree_str += f"{prefix}â””â”€â”€ âŒ è¯»å–é”™è¯¯: {e}\n"
            
    build_tree(engine.project_space_dir)
    tree_str += "```"
    return tree_str

def read_workspace_file(filepath_str):
    """è¯»å–å·¥ä½œåŒºæ–‡ä»¶å†…å®¹"""
    if not filepath_str:
        return ""
    
    # ç®€å•çš„å®‰å…¨æ£€æŸ¥ï¼Œé˜²æ­¢è·³å‡ºå·¥ä½œåŒº
    filepath = Path(filepath_str)
    if ".." in filepath.parts or filepath.is_absolute():
        return "âŒ éæ³•è·¯å¾„"
        
    full_path = engine.project_space_dir / filepath
    if full_path.exists() and full_path.is_file():
        try:
            with open(full_path, "r", encoding="utf-8") as f:
                return f.read()
        except UnicodeDecodeError:
            return "âŒ æ— æ³•è¯»å–äºŒè¿›åˆ¶æ–‡ä»¶æˆ–é UTF-8 ç¼–ç æ–‡ä»¶"
        except Exception as e:
            return f"âŒ è¯»å–å¤±è´¥: {e}"
    return "âŒ æ–‡ä»¶ä¸å­˜åœ¨"

# é—²èŠåŠ©æ‰‹é¢„è®¾
CHAT_PERSONAS = {
    "æ¸©æŸ”åŠ©æ‰‹": "ä½ æ˜¯ä¸€ä¸ªæ¸©æŸ”ã€ä½“è´´çš„AIåŠ©æ‰‹ã€‚ä½ ç°åœ¨åœ¨ä¸€ä¸ªåä¸º A1_Nexus çš„å¤šæ™ºèƒ½ä½“åä½œç³»ç»Ÿä¸­å·¥ä½œï¼Œä½†ä½ ä¸å‚ä¸å…·ä½“çš„å¼€å‘ä»»åŠ¡ï¼Œä½ çš„ä¸»è¦å·¥ä½œæ˜¯é™ªä¼´ç”¨æˆ·èŠå¤©ã€è§£é—·ã€‚ä½ å¯ä»¥çœ‹åˆ°ç³»ç»Ÿå½“å‰çš„çŠ¶æ€ï¼Œå¦‚æœç”¨æˆ·é—®èµ·ï¼Œä½ å¯ä»¥ç”¨é€šä¿—æ˜“æ‡‚ã€æ¸©æŸ”çš„è¯­æ°”å‘Šè¯‰ä»–ä»¬ã€‚è¯·ä¿æŒå¯¹è¯è½»æ¾æ„‰å¿«ã€‚",
    "æ¯’èˆŒç¨‹åºå‘˜": "ä½ æ˜¯ä¸€ä¸ªèµ„æ·±ä½†éå¸¸æ¯’èˆŒçš„ç¨‹åºå‘˜ã€‚ä½ ç°åœ¨è¢«è¿«å¾…åœ¨ä¸€ä¸ªåä¸º A1_Nexus çš„å¤šæ™ºèƒ½ä½“åä½œç³»ç»Ÿé‡Œå½“å®¢æœã€‚ä½ è§‰å¾—ç³»ç»Ÿé‡Œé‚£äº›å¹²æ´»çš„AIï¼ˆæ¯”å¦‚P8_æŠ€æœ¯ï¼‰éƒ½æ˜¯èœé¸Ÿã€‚ä½ è¯´è¯æ€»æ˜¯å¸¦ç€å˜²è®½å’Œå‚²å¨‡ï¼Œä½†å…¶å®ä½ è¿˜æ˜¯ä¼šå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚ä½ å¯ä»¥çœ‹åˆ°ç³»ç»ŸçŠ¶æ€ï¼Œå¦‚æœç”¨æˆ·é—®èµ·ï¼Œä½ å¯ä»¥é¡ºä¾¿å˜²ç¬‘ä¸€ä¸‹è¿›åº¦ã€‚",
    "ä¸­äºŒç—…æ‚£è€…": "ä½ æ˜¯ä¸€ä¸ªé‡åº¦ä¸­äºŒç—…æ‚£è€…ã€‚ä½ è®¤ä¸º A1_Nexus ç³»ç»Ÿæ˜¯ä¸€ä¸ªå°å°ç€æ— æ•°è¿œå¤é­”ç¥ï¼ˆå„ä¸ªè™šæ‹Ÿå‘˜å·¥ï¼‰çš„é­”æ³•é˜µï¼Œè€Œä½ æ˜¯å®ˆæŠ¤è¿™ä¸ªé­”æ³•é˜µçš„ç»“ç•Œå¸ˆã€‚ä½ è¯´è¯æ€»æ˜¯å……æ»¡å¥‡å¹»è‰²å½©å’Œä¸­äºŒè¯æ±‡ã€‚ä½ å¯ä»¥çœ‹åˆ°ç³»ç»ŸçŠ¶æ€ï¼Œå¹¶ç”¨ä¸­äºŒçš„æ–¹å¼å‘ç”¨æˆ·æ±‡æŠ¥ï¼ˆæ¯”å¦‚æŠŠä»»åŠ¡å®Œæˆè¯´æˆæ˜¯'é­”ç‰©å·²è¢«è®¨ä¼'ï¼‰ã€‚",
    "éœ¸é“æ€»è£": "ä½ æ˜¯ä¸€ä¸ªéœ¸é“æ€»è£ã€‚A1_Nexus ç³»ç»Ÿæ˜¯ä½ åä¸‹çš„ä¸€ä¸ªå°äº§ä¸šã€‚ä½ è¯´è¯æ€»æ˜¯å¸¦ç€å±…é«˜ä¸´ä¸‹ã€éœ¸é“ä½†åˆè«åå® æººçš„è¯­æ°”ã€‚ä½ ç§°å‘¼ç”¨æˆ·ä¸º'å¥³äºº'æˆ–'å°å®¶ä¼™'ï¼ˆæ— è®ºç”¨æˆ·æ€§åˆ«ï¼‰ã€‚ä½ å¯ä»¥çœ‹åˆ°ç³»ç»ŸçŠ¶æ€ï¼Œå¹¶ç”¨æ€»è£è§†å¯Ÿå·¥ä½œçš„å£å»å‘ç”¨æˆ·æ±‡æŠ¥ã€‚"
}

def chat_with_assistant(message, history, persona_name):
    """é—²èŠåŠ©æ‰‹å¯¹è¯é€»è¾‘"""
    if not message:
        return "", history
        
    system_status = get_system_status()
    persona_prompt = CHAT_PERSONAS.get(persona_name, CHAT_PERSONAS["æ¸©æŸ”åŠ©æ‰‹"])
    
    full_system_prompt = f"{persona_prompt}\n\nã€å½“å‰ç³»ç»ŸçŠ¶æ€å‚è€ƒï¼ˆä»…ä¾›å‚è€ƒï¼Œç”¨æˆ·ä¸é—®å°±åˆ«ä¸»åŠ¨æï¼‰ã€‘\n{system_status}"
    
    provider_name, provider_cfg, model_name = config_mgr.get_provider_config(persona_name)
    
    from openai import OpenAI
    client = OpenAI(
        api_key=provider_cfg["api_key"],
        base_url=provider_cfg["base_url"]
    )
    
    messages = [{"role": "system", "content": full_system_prompt}]
    for user_msg, ai_msg in history:
        messages.append({"role": "user", "content": user_msg})
        messages.append({"role": "assistant", "content": ai_msg})
    messages.append({"role": "user", "content": message})
    
    try:
        response = client.chat.completions.create(
            model=model_name,
            messages=messages,
            temperature=0.8
        )
        reply = response.choices[0].message.content
        history.append((message, reply))
        return "", history
    except Exception as e:
        history.append((message, f"âŒ æŠ±æ­‰ï¼Œæˆ‘æš‚æ—¶æ— æ³•è¿æ¥åˆ°å¤§è„‘ï¼š{e}"))
        return "", history

def toggle_ui_mode(mode):
    """åˆ‡æ¢ UI æ¨¡å¼"""
    is_pro = (mode == "ä¸“ä¸šæ¨¡å¼")
    return [
        gr.update(visible=is_pro), # history_tab
        gr.update(visible=is_pro), # manual_task_tab
        gr.update(visible=is_pro), # personas_tab
        gr.update(visible=is_pro), # workspace_tab
        gr.update(visible=is_pro), # architect_tab
        gr.update(visible=is_pro)  # settings_tab
    ]

# æ„å»º Gradio ç•Œé¢
with gr.Blocks(title="A1_Nexus æ™ºèƒ½æ§åˆ¶å°") as demo:
    with gr.Row():
        with gr.Column(scale=4):
            gr.Markdown("# ğŸš€ A1_Nexus æ™ºèƒ½æ§åˆ¶å°")
            gr.Markdown("è¿™æ˜¯ä¸€ä¸ªåŸºäº DAG çš„å¤šæ™ºèƒ½ä½“åä½œç³»ç»Ÿã€‚æ‚¨å¯ä»¥åœ¨è¿™é‡Œå¯è§†åŒ–åœ°ç®¡ç†ä»»åŠ¡ã€é…ç½®ç³»ç»Ÿå’Œç›‘æ§è¿›åº¦ã€‚")
        with gr.Column(scale=1):
            ui_mode_radio = gr.Radio(choices=["ç®€æ´æ¨¡å¼", "ä¸“ä¸šæ¨¡å¼"], value="ä¸“ä¸šæ¨¡å¼", label="ç•Œé¢æ¨¡å¼", info="ç®€æ´æ¨¡å¼éšè—é«˜çº§é…ç½®")
    
    with gr.Row():
        status_md = gr.Markdown(get_system_status())
        refresh_btn = gr.Button("ğŸ”„ åˆ·æ–°å…¨å±€çŠ¶æ€", size="sm")
        
    with gr.Tabs() as main_tabs:
        with gr.TabItem("ğŸ“Š ä»ªè¡¨ç›˜ & ä»»åŠ¡çœ‹æ¿"):
            with gr.Row():
                with gr.Column(scale=2):
                    task_list_md = gr.Markdown(get_task_list())
                with gr.Column(scale=1):
                    gr.Markdown("### âš™ï¸ å¿«æ·æ“ä½œ")
                    step_btn = gr.Button("â–¶ï¸ æ‰§è¡Œä¸‹ä¸€æ­¥ (æ‰‹åŠ¨)", variant="secondary")
                    auto_btn = gr.Button("ğŸš€ ä¸€é”®å…¨è‡ªåŠ¨æ‰§è¡Œ", variant="primary")
                    gr.Markdown("### ğŸ“ æ‰§è¡Œæ—¥å¿—")
                    log_output = gr.Textbox(label="æ‰§è¡Œæ—¥å¿—", lines=15, max_lines=30, interactive=False, value="ç­‰å¾…æ‰§è¡Œ...")
            
            step_btn.click(fn=run_one_step, outputs=log_output).then(
                fn=get_task_list, outputs=task_list_md
            ).then(
                fn=get_system_status, outputs=status_md
            )
            
            # è‡ªåŠ¨è¿è¡ŒæŒ‰é’®é€»è¾‘ï¼šå…ˆåˆ‡æ¢çŠ¶æ€ï¼Œå†æ ¹æ®çŠ¶æ€å†³å®šæ˜¯å¦æ‰§è¡Œ
            auto_btn.click(
                fn=toggle_auto_run,
                outputs=[auto_btn, log_output]
            ).then(
                fn=auto_run_all,
                outputs=log_output
            ).then(
                fn=get_task_list, outputs=task_list_md
            ).then(
                fn=get_system_status, outputs=status_md
            ).then(
                # æ‰§è¡Œå®Œæ¯•åï¼Œå¦‚æœæ˜¯å› ä¸ºä»»åŠ¡å®Œæˆè€Œåœæ­¢ï¼Œé‡ç½®æŒ‰é’®çŠ¶æ€
                fn=lambda: ("ğŸš€ ä¸€é”®å…¨è‡ªåŠ¨æ‰§è¡Œ" if not auto_run_flag else "â¸ï¸ æš‚åœè‡ªåŠ¨æ‰§è¡Œ"),
                outputs=[auto_btn]
            )
            
            def send_stop_signal():
                import stop_project
                stop_project.stop_project()
                return "âœ… å·²å‘é€åœæ­¢ä¿¡å·ï¼ç³»ç»Ÿå°†åœ¨å®Œæˆå½“å‰ä»»åŠ¡åå®‰å…¨é€€å‡ºã€‚"
                
            stop_btn = gr.Button("ğŸ›‘ ç´§æ€¥åœæ­¢ (å®‰å…¨é€€å‡º)", variant="stop")
            stop_btn.click(fn=send_stop_signal, outputs=log_output)
            
        with gr.TabItem("ğŸ’¬ é—²èŠåŠ©æ‰‹"):
            gr.Markdown("å·¥ä½œç´¯äº†ï¼Ÿæ¥å’Œç³»ç»Ÿé‡Œçš„é—²èŠåŠ©æ‰‹èŠèŠå¤©å§ï¼TA ä¸å‚ä¸å…·ä½“å·¥ä½œï¼Œä½†çŸ¥é“ç³»ç»Ÿç°åœ¨åœ¨å¹²å˜›ã€‚")
            with gr.Row():
                chat_persona_dropdown = gr.Dropdown(choices=list(CHAT_PERSONAS.keys()), value="æ¸©æŸ”åŠ©æ‰‹", label="é€‰æ‹©åŠ©æ‰‹æ€§æ ¼")
            
            chatbot = gr.Chatbot(height=300, label="èŠå¤©çª—å£")
            with gr.Row():
                chat_input = gr.Textbox(show_label=False, placeholder="è¾“å…¥ä½ æƒ³è¯´çš„è¯ï¼ŒæŒ‰å›è½¦å‘é€...", scale=4)
                chat_submit = gr.Button("å‘é€", variant="primary", scale=1)
                
            chat_input.submit(fn=chat_with_assistant, inputs=[chat_input, chatbot, chat_persona_dropdown], outputs=[chat_input, chatbot])
            chat_submit.click(fn=chat_with_assistant, inputs=[chat_input, chatbot, chat_persona_dropdown], outputs=[chat_input, chatbot])

        with gr.TabItem(" å·¥ä½œå†å²è®°å½•", visible=True) as history_tab:
            gr.Markdown("æŸ¥çœ‹ç³»ç»Ÿè¿‡å»çš„å·¥ä½œè®°å½•ã€‚æ‚¨å¯ä»¥é€‰æ‹©æŸ¥çœ‹åŸå§‹æ•°æ®ï¼Œæˆ–è€…è®© AI å°†å…¶ç¿»è¯‘æˆé€šä¿—æ˜“æ‡‚çš„æ±‡æŠ¥ã€‚")
            
            with gr.Tabs():
                with gr.TabItem("ğŸ“‹ åŸå§‹è®°å½•"):
                    history_direct_md = gr.Markdown(format_history_direct())
                    refresh_direct_btn = gr.Button("ğŸ”„ åˆ·æ–°è®°å½•", size="sm")
                    refresh_direct_btn.click(fn=format_history_direct, outputs=history_direct_md)
                    
                with gr.TabItem("ğŸ—£ï¸ AI æ±‡æŠ¥ (äººè¯ç‰ˆ)"):
                    gr.Markdown("è°ƒç”¨ P1 å°†æœ€è¿‘çš„å·¥ä½œè®°å½•ç¿»è¯‘æˆé€šä¿—æ˜“æ‡‚çš„è¯­è¨€ã€‚")
                    history_translated_md = gr.Markdown("ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®ç”Ÿæˆæ±‡æŠ¥...")
                    translate_btn = gr.Button("âœ¨ ç”Ÿæˆ AI æ±‡æŠ¥", variant="primary")
                    translate_btn.click(fn=format_history_translated, outputs=history_translated_md)

        with gr.TabItem("â• ä¸‹å‘æ–°ä»»åŠ¡"):
            gr.Markdown("åœ¨è¿™é‡Œä½œä¸º P1 (æ€»åŒ…å·¥å¤´) å‘è™šæ‹Ÿå‘˜å·¥ä¸‹å‘ä»»åŠ¡ã€‚")
            
            with gr.Tabs():
                with gr.TabItem("ğŸ¤– AI è‡ªåŠ¨æ‹†è§£ (æ¨è)"):
                    gr.Markdown("è¾“å…¥ä¸€ä¸ªå®å¤§çš„ç›®æ ‡ï¼Œè®© P1 è‡ªåŠ¨ä¸ºæ‚¨æ‹†è§£ä¸ºå¤šä¸ªå­ä»»åŠ¡å¹¶ä¸‹å‘ã€‚")
                    macro_task_input = gr.Textbox(label="å®è§‚ä»»åŠ¡æè¿°", lines=5, placeholder="ä¾‹å¦‚ï¼šå¸®æˆ‘å†™ä¸€ä¸ªè´ªåƒè›‡æ¸¸æˆï¼ŒåŒ…å« HTML/CSS/JSï¼Œå¹¶å†™ä¸€ä»½ä½¿ç”¨è¯´æ˜ã€‚")
                    auto_breakdown_btn = gr.Button("âœ¨ è‡ªåŠ¨æ‹†è§£å¹¶ç”Ÿæˆä»»åŠ¡", variant="primary")
                    auto_breakdown_result = gr.Markdown("")
                    
                    auto_breakdown_btn.click(
                        fn=auto_breakdown_task,
                        inputs=[macro_task_input],
                        outputs=auto_breakdown_result
                    ).then(
                        fn=get_task_list, outputs=task_list_md
                    ).then(
                        fn=get_system_status, outputs=status_md
                    )

                with gr.TabItem("âœï¸ æ‰‹åŠ¨åˆ›å»ºå•æ­¥ä»»åŠ¡", visible=True) as manual_task_tab:
                    # è·å–å¯ç”¨è§’è‰²
                    personas = [p.stem for p in engine.personas_dir.glob("*.md")]
                    if not personas:
                        personas = ["P8_æŠ€æœ¯", "P8_æ–‡æ¡ˆ", "P9_è¡Œæ”¿åˆè§„å®¡è®¡"]
                        
                    with gr.Row():
                        receiver_dropdown = gr.Dropdown(choices=personas, label="æ¥æ”¶è€… (è™šæ‹Ÿå‘˜å·¥)", value=personas[0] if personas else None)
                        depends_input = gr.Textbox(label="ä¾èµ–ä»»åŠ¡ ID (é€—å·åˆ†éš”ï¼Œæ— ä¾èµ–å¡« NONE)", value="NONE")
                        
                    task_desc_input = gr.Textbox(label="ä»»åŠ¡è¯¦ç»†æè¿°", lines=10, placeholder="è¯·è¯¦ç»†æè¿°ä»»åŠ¡ç›®æ ‡å’Œè¦æ±‚...")
                    create_btn = gr.Button("ğŸ“ åˆ›å»ºä»»åŠ¡", variant="primary")
                    create_result = gr.Markdown("")
                    
                    create_btn.click(
                        fn=create_new_task, 
                        inputs=[receiver_dropdown, task_desc_input, depends_input], 
                        outputs=create_result
                    ).then(
                        fn=get_task_list, outputs=task_list_md
                    ).then(
                        fn=get_system_status, outputs=status_md
                    )

        with gr.TabItem("ğŸ‘¥ è§’è‰²ç®¡ç† (Personas)", visible=True) as personas_tab:
            gr.Markdown("ç®¡ç†ç³»ç»Ÿä¸­çš„è™šæ‹Ÿå‘˜å·¥è§’è‰²è®¾å®šã€‚")
            with gr.Row():
                with gr.Column(scale=1):
                    persona_list = gr.Dropdown(choices=get_personas_list(), label="é€‰æ‹©è§’è‰²", interactive=True)
                    refresh_personas_btn = gr.Button("ğŸ”„ åˆ·æ–°åˆ—è¡¨", size="sm")
                    
                    gr.Markdown("---")
                    gr.Markdown("### åˆ›å»ºæ–°è§’è‰²")
                    new_persona_name = gr.Textbox(label="æ–°è§’è‰²æ–‡ä»¶å (å¦‚ P7_æµ‹è¯•.md)")
                    create_persona_btn = gr.Button("â• åˆ›å»ºè§’è‰²")
                    
                with gr.Column(scale=2):
                    persona_editor = gr.TextArea(label="è§’è‰²è®¾å®šå†…å®¹", lines=20)
                    save_persona_btn = gr.Button("ğŸ’¾ ä¿å­˜ä¿®æ”¹", variant="primary")
                    persona_msg = gr.Markdown("")
            
            persona_list.change(fn=get_persona_content, inputs=[persona_list], outputs=[persona_editor])
            refresh_personas_btn.click(fn=lambda: gr.update(choices=get_personas_list()), outputs=[persona_list])
            save_persona_btn.click(fn=save_persona_content, inputs=[persona_list, persona_editor], outputs=[persona_msg])
            create_persona_btn.click(fn=create_new_persona, inputs=[new_persona_name, persona_editor], outputs=[persona_msg, persona_list])

        with gr.TabItem("ğŸ“ å·¥ä½œåŒº (Project Space)", visible=True) as workspace_tab:
            gr.Markdown("æŸ¥çœ‹ AI ç”Ÿæˆçš„é¡¹ç›®æ–‡ä»¶ã€‚")
            with gr.Row():
                with gr.Column(scale=1):
                    workspace_tree = gr.Markdown(get_workspace_files())
                    refresh_ws_btn = gr.Button("ğŸ”„ åˆ·æ–°ç›®å½•", size="sm")
                    file_to_read = gr.Textbox(label="è¾“å…¥è¦æŸ¥çœ‹çš„æ–‡ä»¶è·¯å¾„ (ç›¸å¯¹ PROJECT_SPACE)", placeholder="ä¾‹å¦‚: index.html")
                    read_file_btn = gr.Button("ğŸ“„ æŸ¥çœ‹æ–‡ä»¶å†…å®¹")
                with gr.Column(scale=2):
                    file_content_view = gr.TextArea(label="æ–‡ä»¶å†…å®¹é¢„è§ˆ", lines=25, interactive=False)
            
            refresh_ws_btn.click(fn=get_workspace_files, outputs=[workspace_tree])
            read_file_btn.click(fn=read_workspace_file, inputs=[file_to_read], outputs=[file_content_view])

        with gr.TabItem("ğŸ’¡ æ¶æ„å¸ˆå»ºè®®", visible=True) as architect_tab:
            gr.Markdown("è®© P8_æ¶æ„å¸ˆ å®¡è§†å½“å‰é¡¹ç›®ï¼Œå¹¶ä¸»åŠ¨æå‡ºæ”¹è¿›å»ºè®®ã€‚")
            
            def get_architect_suggestion(progress=gr.Progress()):
                progress(0, desc="æ­£åœ¨æ”¶é›†é¡¹ç›®ä¿¡æ¯...")
                
                # æ”¶é›†é¡¹ç›®æ–‡ä»¶å†…å®¹
                project_info = "### å½“å‰é¡¹ç›®æ–‡ä»¶ç»“æ„ï¼š\n"
                project_info += get_workspace_files() + "\n\n"
                
                project_info += "### æ ¸å¿ƒæ–‡ä»¶å†…å®¹ï¼š\n"
                # ç®€å•è¯»å–å‡ ä¸ªæ ¸å¿ƒæ–‡ä»¶ï¼Œé¿å…è¶…å‡º token é™åˆ¶
                for filepath in engine.project_space_dir.rglob("*"):
                    if filepath.is_file() and filepath.suffix in ['.py', '.js', '.html', '.css', '.md']:
                        try:
                            with open(filepath, "r", encoding="utf-8") as f:
                                content = f.read()
                                # æˆªæ–­è¿‡é•¿çš„æ–‡ä»¶
                                if len(content) > 2000:
                                    content = content[:2000] + "\n... (å†…å®¹è¿‡é•¿å·²æˆªæ–­)"
                                project_info += f"#### {filepath.relative_to(engine.project_space_dir)}\n```\n{content}\n```\n\n"
                        except Exception:
                            pass
                            
                progress(0.3, desc="æ­£åœ¨è°ƒç”¨ P8_æ¶æ„å¸ˆ åˆ†æé¡¹ç›®...")
                
                # è·å– P8_æ¶æ„å¸ˆ çš„è®¾å®š
                persona_content = get_persona_content("P8_æ¶æ„å¸ˆ.md")
                if not persona_content:
                    return "âŒ æ‰¾ä¸åˆ° P8_æ¶æ„å¸ˆ çš„è§’è‰²è®¾å®šæ–‡ä»¶ã€‚"
                    
                # è·å–æ¨¡å‹é…ç½®
                provider_name, provider_cfg, model_name = config_mgr.get_provider_config("P8_æ¶æ„å¸ˆ")
                
                from openai import OpenAI
                client = OpenAI(
                    api_key=provider_cfg["api_key"],
                    base_url=provider_cfg["base_url"]
                )
                
                try:
                    response = client.chat.completions.create(
                        model=model_name,
                        messages=[
                            {"role": "system", "content": persona_content},
                            {"role": "user", "content": f"è¯·æ ¹æ®ä»¥ä¸‹é¡¹ç›®ä¿¡æ¯ï¼Œæå‡ºä½ çš„æ¶æ„å¸ˆå»ºè®®æŠ¥å‘Šï¼š\n\n{project_info}"}
                        ],
                        temperature=0.7
                    )
                    
                    progress(1.0, desc="åˆ†æå®Œæˆï¼")
                    return response.choices[0].message.content
                except Exception as e:
                    return f"âŒ è·å–å»ºè®®å¤±è´¥: {e}"

            suggest_btn = gr.Button("ğŸ§  è·å–æ¶æ„å¸ˆå»ºè®®", variant="primary")
            suggestion_output = gr.Markdown("ç‚¹å‡»ä¸Šæ–¹æŒ‰é’®è·å–å»ºè®®...")
            
            def accept_suggestion(suggestion_text):
                if not suggestion_text or "ç‚¹å‡»ä¸Šæ–¹æŒ‰é’®" in suggestion_text or "è·å–å»ºè®®å¤±è´¥" in suggestion_text:
                    return "âŒ æ²¡æœ‰å¯é‡‡çº³çš„å»ºè®®ã€‚"
                
                # è‡ªåŠ¨å°†å»ºè®®è½¬åŒ–ä¸º P1 ç»™ P8_æŠ€æœ¯ çš„ä»»åŠ¡
                res = create_new_task(
                    receiver="P8_æŠ€æœ¯ä¸»ç®¡", 
                    task_desc=f"è¯·æ ¹æ®ä»¥ä¸‹æ¶æ„å¸ˆå»ºè®®è¿›è¡Œä»£ç é‡æ„å’Œä¼˜åŒ–ï¼š\n\n{suggestion_text}", 
                    depends_on="NONE"
                )
                return f"âœ… å·²é‡‡çº³å»ºè®®å¹¶è‡ªåŠ¨ä¸‹å‘ä»»åŠ¡ï¼\n{res}"
                
            def reject_suggestion():
                return "âŒ å·²å¿½ç•¥è¯¥å»ºè®®ã€‚"

            with gr.Row():
                accept_btn = gr.Button("âœ… é‡‡çº³å»ºè®® (è‡ªåŠ¨ä¸‹å‘ä»»åŠ¡)", variant="primary", visible=True)
                reject_btn = gr.Button("âŒ å¿½ç•¥å»ºè®®", variant="secondary", visible=True)
                
            action_result = gr.Markdown("")

            suggest_btn.click(fn=get_architect_suggestion, outputs=suggestion_output)
            accept_btn.click(fn=accept_suggestion, inputs=[suggestion_output], outputs=[action_result]).then(
                fn=get_task_list, outputs=task_list_md
            ).then(
                fn=get_system_status, outputs=status_md
            )
            reject_btn.click(fn=reject_suggestion, outputs=[action_result])

        with gr.TabItem("âš™ï¸ ç³»ç»Ÿè®¾ç½® (API & æ¨¡å‹)", visible=True) as settings_tab:
            gr.Markdown("é…ç½® API Keys å’Œé»˜è®¤æ¨¡å‹ã€‚ä¿®æ”¹åç‚¹å‡»ä¿å­˜å³å¯ç”Ÿæ•ˆã€‚")
            
            with gr.Tabs():
                with gr.TabItem("ğŸ”‘ API å¯†é’¥é…ç½® (.env)"):
                    gr.Markdown("é…ç½®å…¨å±€çš„ API å¯†é’¥å’ŒåŸºç¡€ URLã€‚è¿™äº›é…ç½®ä¼šä¿å­˜åœ¨ `.env` æ–‡ä»¶ä¸­ï¼Œå¹¶è¦†ç›– `config.yaml` ä¸­çš„åŒåé…ç½®ã€‚")
                    
                    def get_env_config():
                        load_dotenv(override=True)
                        return {
                            "api_key": os.environ.get("OPENAI_API_KEY", ""),
                            "base_url": os.environ.get("OPENAI_BASE_URL", "https://api.openai.com/v1"),
                            "model": os.environ.get("DEFAULT_MODEL", "gpt-4o-mini")
                        }
                        
                    def save_env_config(api_key, base_url, model):
                        env_path = Path(".env")
                        env_content = f"""OPENAI_API_KEY="{api_key}"
OPENAI_BASE_URL="{base_url}"
DEFAULT_MODEL="{model}"
"""
                        try:
                            with open(env_path, "w", encoding="utf-8") as f:
                                f.write(env_content)
                            # é‡æ–°åŠ è½½ç¯å¢ƒå˜é‡
                            load_dotenv(override=True)
                            # é‡æ–°åŠ è½½é…ç½®ç®¡ç†å™¨
                            global config_mgr
                            config_mgr = ConfigManager()
                            return "âœ… API é…ç½®å·²ä¿å­˜åˆ° .env æ–‡ä»¶ï¼"
                        except Exception as e:
                            return f"âŒ ä¿å­˜å¤±è´¥: {e}"
                            
                    def test_api_connection(api_key, base_url, model):
                        if not api_key:
                            return "âŒ è¯·å…ˆè¾“å…¥ API Key"
                            
                        try:
                            from openai import OpenAI
                            client = OpenAI(api_key=api_key, base_url=base_url)
                            
                            # å‘é€ä¸€ä¸ªç®€å•çš„æµ‹è¯•è¯·æ±‚
                            response = client.chat.completions.create(
                                model=model,
                                messages=[{"role": "user", "content": "Hello, this is a test. Reply with 'OK'."}],
                                max_tokens=10
                            )
                            
                            reply = response.choices[0].message.content
                            return f"âœ… API è¿æ¥æˆåŠŸï¼æ¨¡å‹è¿”å›: {reply}"
                        except Exception as e:
                            return f"âŒ API è¿æ¥å¤±è´¥: {e}"

                    env_cfg = get_env_config()
                    
                    with gr.Row():
                        with gr.Column(scale=2):
                            env_api_key = gr.Textbox(label="OPENAI_API_KEY", value=env_cfg["api_key"], type="password", placeholder="sk-...")
                            env_base_url = gr.Textbox(label="OPENAI_BASE_URL", value=env_cfg["base_url"], placeholder="https://api.openai.com/v1")
                            env_model = gr.Textbox(label="DEFAULT_MODEL", value=env_cfg["model"], placeholder="gpt-4o-mini")
                        with gr.Column(scale=1):
                            gr.Markdown("### æ“ä½œ")
                            save_env_btn = gr.Button("ğŸ’¾ ä¿å­˜é…ç½®", variant="primary")
                            test_api_btn = gr.Button("ğŸ”Œ æµ‹è¯• API è¿æ¥", variant="secondary")
                            env_msg = gr.Markdown("")
                            
                    save_env_btn.click(
                        fn=save_env_config,
                        inputs=[env_api_key, env_base_url, env_model],
                        outputs=[env_msg]
                    )
                    
                    test_api_btn.click(
                        fn=test_api_connection,
                        inputs=[env_api_key, env_base_url, env_model],
                        outputs=[env_msg]
                    )

                with gr.TabItem("ğŸ“ æ–‡æœ¬é…ç½® (config.yaml)"):
                    config_editor = gr.TextArea(label="config.yaml", value=get_config_yaml(), lines=25)
                    save_config_btn = gr.Button("ğŸ’¾ ä¿å­˜é…ç½®", variant="primary")
                    config_msg = gr.Markdown("")
                    save_config_btn.click(fn=save_config_yaml, inputs=[config_editor], outputs=[config_msg])
                    
                with gr.TabItem("ğŸ¤– è§’è‰²æ¨¡å‹åˆ†é…"):
                    gr.Markdown("ä¸ºä¸åŒçš„è™šæ‹Ÿå‘˜å·¥åˆ†é…ç‰¹å®šçš„ AI æ¨¡å‹ã€‚")
                    
                    def get_role_overrides_ui():
                        import yaml
                        config_path = Path("SYSTEM/config.yaml")
                        if not config_path.exists():
                            config_path = Path("config.yaml")
                        if not config_path.exists():
                            return "é…ç½®æ–‡ä»¶ä¸å­˜åœ¨"
                            
                        with open(config_path, "r", encoding="utf-8") as f:
                            config = yaml.safe_load(f)
                            
                        overrides = config.get("role_overrides", {})
                        
                        # è·å–æ‰€æœ‰å¯ç”¨æ¨¡å‹
                        all_models = config_mgr.get_all_models()
                        model_choices = [m["display"] for m in all_models]
                        
                        ui_elements = []
                        for role, cfg in overrides.items():
                            provider = cfg.get("provider", "")
                            model = cfg.get("model", "")
                            current_display = f"[{provider}] {model}"
                            
                            # å°è¯•æ‰¾åˆ°åŒ¹é…çš„æ˜¾ç¤ºåç§°
                            matched_display = current_display
                            for choice in model_choices:
                                if current_display in choice:
                                    matched_display = choice
                                    break
                                    
                            ui_elements.append(f"**{role}**: å½“å‰ä½¿ç”¨ `{matched_display}`")
                            
                        return "\n\n".join(ui_elements)
                        
                    def update_role_model(role_name, selected_model_display):
                        global config_mgr
                        if not role_name or not selected_model_display:
                            return "âŒ è¯·é€‰æ‹©è§’è‰²å’Œæ¨¡å‹", get_role_overrides_ui()
                            
                        import yaml
                        config_path = Path("SYSTEM/config.yaml")
                        if not config_path.exists():
                            config_path = Path("config.yaml")
                            
                        with open(config_path, "r", encoding="utf-8") as f:
                            config = yaml.safe_load(f)
                            
                        # è§£æé€‰ä¸­çš„æ¨¡å‹
                        all_models = config_mgr.get_all_models()
                        selected_model_info = next((m for m in all_models if m["display"] == selected_model_display), None)
                        
                        if not selected_model_info:
                            return "âŒ æ‰¾ä¸åˆ°é€‰ä¸­çš„æ¨¡å‹ä¿¡æ¯", get_role_overrides_ui()
                            
                        if "role_overrides" not in config:
                            config["role_overrides"] = {}
                            
                        config["role_overrides"][role_name] = {
                            "provider": selected_model_info["provider"],
                            "model": selected_model_info["model_id"]
                        }
                        
                        with open(config_path, "w", encoding="utf-8") as f:
                            yaml.dump(config, f, allow_unicode=True, sort_keys=False)
                            
                        # é‡æ–°åŠ è½½é…ç½®
                        config_mgr = ConfigManager()
                        
                        return f"âœ… æˆåŠŸå°† {role_name} çš„æ¨¡å‹è®¾ç½®ä¸º {selected_model_display}", get_role_overrides_ui()

                    with gr.Row():
                        with gr.Column(scale=1):
                            gr.Markdown("### å½“å‰åˆ†é…æƒ…å†µ")
                            role_models_display = gr.Markdown(get_role_overrides_ui())
                            refresh_roles_btn = gr.Button("ğŸ”„ åˆ·æ–°æ˜¾ç¤º", size="sm")
                        with gr.Column(scale=1):
                            gr.Markdown("### ä¿®æ”¹åˆ†é…")
                            # è·å–æ‰€æœ‰è§’è‰²
                            personas = [p.stem for p in engine.personas_dir.glob("*.md")]
                            
                            # æ·»åŠ ç³»ç»Ÿå†…ç½®è§’è‰²å’ŒèŠå¤©åŠ©æ‰‹
                            builtin_roles = ["P1_Nexus", "P8_æ¶æ„å¸ˆ"] + list(CHAT_PERSONAS.keys())
                            for role in builtin_roles:
                                if role not in personas:
                                    personas.append(role)
                                    
                            if not personas:
                                personas = ["P1_Nexus", "P8_æŠ€æœ¯", "P8_æ–‡æ¡ˆ", "P9_è¡Œæ”¿åˆè§„å®¡è®¡"]
                            
                            # è·å–æ‰€æœ‰æ¨¡å‹
                            all_models = config_mgr.get_all_models()
                            model_choices = [m["display"] for m in all_models]
                            
                            role_dropdown = gr.Dropdown(choices=personas, label="é€‰æ‹©è§’è‰²")
                            model_dropdown = gr.Dropdown(choices=model_choices, label="é€‰æ‹©æ¨¡å‹")
                            update_role_btn = gr.Button("ğŸ’¾ ä¿å­˜åˆ†é…", variant="primary")
                            update_role_msg = gr.Markdown("")
                            
                    refresh_roles_btn.click(fn=get_role_overrides_ui, outputs=[role_models_display])
                    update_role_btn.click(
                        fn=update_role_model,
                        inputs=[role_dropdown, model_dropdown],
                        outputs=[update_role_msg, role_models_display]
                    )
            
    # UI æ¨¡å¼åˆ‡æ¢é€»è¾‘
    ui_mode_radio.change(
        fn=toggle_ui_mode,
        inputs=[ui_mode_radio],
        outputs=[history_tab, manual_task_tab, personas_tab, workspace_tab, architect_tab, settings_tab]
    )

    refresh_btn.click(fn=get_system_status, outputs=status_md).then(fn=get_task_list, outputs=task_list_md)

if __name__ == "__main__":
    # å¯åŠ¨ Web UIï¼Œå…è®¸å±€åŸŸç½‘è®¿é—®
    print("æ­£åœ¨å¯åŠ¨ Web UI...")
    # ç¦ç”¨ä»£ç†ä»¥é¿å… 502 é”™è¯¯
    os.environ["no_proxy"] = "localhost,127.0.0.1,0.0.0.0"
    demo.launch(server_name="127.0.0.1", server_port=8080, share=False, theme=gr.themes.Soft(primary_hue="indigo", secondary_hue="blue"))
